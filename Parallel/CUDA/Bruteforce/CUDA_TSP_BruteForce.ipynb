{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOukRikJhtdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb44273e-d32c-419e-ef26-ee66c7027037"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nh-69713hvps",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a5dba2f-b098-4441-8862-cd75abf52352"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvcc4jupyter\n",
            "  Downloading nvcc4jupyter-1.2.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Downloading nvcc4jupyter-1.2.1-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install nvcc4jupyter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJaAiw7Zh299",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6be5e45-80af-4284-c23b-c6043bb6a669"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected platform \"Colab\". Running its setup...\n",
            "Source files will be saved in \"/tmp/tmpua0yfkux\".\n"
          ]
        }
      ],
      "source": [
        "%load_ext nvcc4jupyter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAk9MExcECNx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cf5db45-00b6-4ce1-cd9b-4e4049c11a23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nodes: 3, Shortest Path: 157, Execution Time: 0.000071 seconds\n",
            "Nodes: 4, Shortest Path: 200, Execution Time: 0.000024 seconds\n",
            "Nodes: 5, Shortest Path: 196, Execution Time: 0.000023 seconds\n",
            "Nodes: 6, Shortest Path: 182, Execution Time: 0.000024 seconds\n",
            "Nodes: 7, Shortest Path: 170, Execution Time: 0.000026 seconds\n",
            "Nodes: 8, Shortest Path: 162, Execution Time: 0.000039 seconds\n",
            "Nodes: 9, Shortest Path: 135, Execution Time: 0.000037 seconds\n",
            "Nodes: 10, Shortest Path: 122, Execution Time: 0.000162 seconds\n",
            "Nodes: 11, Shortest Path: 145, Execution Time: 0.001678 seconds\n",
            "Nodes: 12, Shortest Path: 102, Execution Time: 0.019594 seconds\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%cuda\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <curand_kernel.h>\n",
        "#include <sys/time.h>\n",
        "\n",
        "#define MAX_NODES 12  // Maximum number of nodes\n",
        "#define BLOCK_SIZE 256\n",
        "\n",
        "__device__ int d_factorial(int n) {\n",
        "    int result = 1;\n",
        "    for (int i = 2; i <= n; ++i) {\n",
        "        result *= i;\n",
        "    }\n",
        "    return result;\n",
        "}\n",
        "\n",
        "// Host version of factorial\n",
        "int h_factorial(int n) {\n",
        "    int result = 1;\n",
        "    for (int i = 2; i <= n; ++i) {\n",
        "        result *= i;\n",
        "    }\n",
        "    return result;\n",
        "}\n",
        "\n",
        "__global__ void tspKernel(int *d_adjacency, int *d_result, int nodes) {\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int total_permutations = d_factorial(nodes - 1);\n",
        "\n",
        "    if (tid < total_permutations) {\n",
        "        int path[MAX_NODES];\n",
        "        for (int i = 0; i < nodes; ++i) {\n",
        "            path[i] = i;\n",
        "        }\n",
        "\n",
        "        // Generate permutation\n",
        "        int temp = tid;\n",
        "        for (int i = 1; i < nodes - 1; ++i) {\n",
        "            int j = temp % (nodes - i) + i;\n",
        "            int swap = path[i];\n",
        "            path[i] = path[j];\n",
        "            path[j] = swap;\n",
        "            temp /= (nodes - i);\n",
        "        }\n",
        "\n",
        "        // Calculate path length\n",
        "        int length = 0;\n",
        "        for (int i = 0; i < nodes - 1; ++i) {\n",
        "            length += d_adjacency[path[i] * nodes + path[i + 1]];\n",
        "        }\n",
        "        length += d_adjacency[path[nodes - 1] * nodes + path[0]];\n",
        "\n",
        "        atomicMin(d_result, length);\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void initRNG(curandState *state, unsigned long seed) {\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    curand_init(seed, tid, 0, &state[tid]);\n",
        "}\n",
        "\n",
        "__global__ void generateAdjacencyMatrix(int *d_adjacency, int nodes, curandState *state) {\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (tid < nodes * nodes) {\n",
        "        int row = tid / nodes;\n",
        "        int col = tid % nodes;\n",
        "        if (row != col) {\n",
        "            d_adjacency[tid] = curand(&state[tid]) % 100 + 1;  // Random distance between 1 and 100\n",
        "        } else {\n",
        "            d_adjacency[tid] = 0;  // Distance to self is 0\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "double getTime() {\n",
        "    struct timeval tv;\n",
        "    gettimeofday(&tv, NULL);\n",
        "    return tv.tv_sec + tv.tv_usec * 1e-6;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    for (int nodes = 3; nodes <= MAX_NODES; ++nodes) {\n",
        "        int *h_adjacency = (int *)malloc(nodes * nodes * sizeof(int));\n",
        "        int *d_adjacency;\n",
        "        cudaMalloc(&d_adjacency, nodes * nodes * sizeof(int));\n",
        "\n",
        "        int *d_result;\n",
        "        cudaMalloc(&d_result, sizeof(int));\n",
        "\n",
        "        curandState *d_state;\n",
        "        cudaMalloc(&d_state, nodes * nodes * sizeof(curandState));\n",
        "\n",
        "        // Initialize RNG\n",
        "        initRNG<<<(nodes * nodes + BLOCK_SIZE - 1) / BLOCK_SIZE, BLOCK_SIZE>>>(d_state, time(NULL));\n",
        "\n",
        "        // Generate adjacency matrix\n",
        "        generateAdjacencyMatrix<<<(nodes * nodes + BLOCK_SIZE - 1) / BLOCK_SIZE, BLOCK_SIZE>>>(d_adjacency, nodes, d_state);\n",
        "\n",
        "        // Copy adjacency matrix to host for verification (optional)\n",
        "        cudaMemcpy(h_adjacency, d_adjacency, nodes * nodes * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "        // Set initial result to a large value\n",
        "        int initial_result = 1000000;\n",
        "        cudaMemcpy(d_result, &initial_result, sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "        int total_permutations = h_factorial(nodes - 1);  // Use host version of factorial\n",
        "        int grid_size = (total_permutations + BLOCK_SIZE - 1) / BLOCK_SIZE;\n",
        "\n",
        "        double start_time = getTime();\n",
        "\n",
        "        // Launch kernel\n",
        "        tspKernel<<<grid_size, BLOCK_SIZE>>>(d_adjacency, d_result, nodes);\n",
        "\n",
        "        // Synchronize and get result\n",
        "        cudaDeviceSynchronize();\n",
        "        int result;\n",
        "        cudaMemcpy(&result, d_result, sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "        double end_time = getTime();\n",
        "        double execution_time = end_time - start_time;\n",
        "\n",
        "        printf(\"Nodes: %d, Shortest Path: %d, Execution Time: %.6f seconds\\n\", nodes, result, execution_time);\n",
        "\n",
        "        // Clean up\n",
        "        free(h_adjacency);\n",
        "        cudaFree(d_adjacency);\n",
        "        cudaFree(d_result);\n",
        "        cudaFree(d_state);\n",
        "    }\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <sys/time.h>\n",
        "\n",
        "#define NODES 4\n",
        "#define BLOCK_SIZE 256\n",
        "\n",
        "__device__ int d_factorial(int n) {\n",
        "    int result = 1;\n",
        "    for (int i = 2; i <= n; ++i) {\n",
        "        result *= i;\n",
        "    }\n",
        "    return result;\n",
        "}\n",
        "\n",
        "int h_factorial(int n) {\n",
        "    int result = 1;\n",
        "    for (int i = 2; i <= n; ++i) {\n",
        "        result *= i;\n",
        "    }\n",
        "    return result;\n",
        "}\n",
        "\n",
        "__global__ void tspKernel(int *d_graph, int *d_result) {\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int total_permutations = d_factorial(NODES - 1);\n",
        "\n",
        "    if (tid < total_permutations) {\n",
        "        int path[NODES];\n",
        "        for (int i = 0; i < NODES; ++i) {\n",
        "            path[i] = i;\n",
        "        }\n",
        "\n",
        "        // Generate permutation\n",
        "        int temp = tid;\n",
        "        for (int i = 1; i < NODES - 1; ++i) {\n",
        "            int j = temp % (NODES - i) + i;\n",
        "            int swap = path[i];\n",
        "            path[i] = path[j];\n",
        "            path[j] = swap;\n",
        "            temp /= (NODES - i);\n",
        "        }\n",
        "\n",
        "        // Calculate path length\n",
        "        int length = 0;\n",
        "        for (int i = 0; i < NODES - 1; ++i) {\n",
        "            length += d_graph[path[i] * NODES + path[i + 1]];\n",
        "        }\n",
        "        length += d_graph[path[NODES - 1] * NODES + path[0]];\n",
        "\n",
        "        atomicMin(d_result, length);\n",
        "    }\n",
        "}\n",
        "\n",
        "double getTime() {\n",
        "    struct timeval tv;\n",
        "    gettimeofday(&tv, NULL);\n",
        "    return tv.tv_sec + tv.tv_usec * 1e-6;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int graph[NODES][NODES] = {\n",
        "        { 0, 10, 15, 20 },\n",
        "        { 10, 0, 35, 25 },\n",
        "        { 15, 35, 0, 30 },\n",
        "        { 20, 25, 30, 0 }\n",
        "    };\n",
        "\n",
        "    int *d_graph;\n",
        "    cudaMalloc(&d_graph, NODES * NODES * sizeof(int));\n",
        "    cudaMemcpy(d_graph, graph, NODES * NODES * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    int *d_result;\n",
        "    cudaMalloc(&d_result, sizeof(int));\n",
        "\n",
        "    // Set initial result to a large value\n",
        "    int initial_result = 1000000;\n",
        "    cudaMemcpy(d_result, &initial_result, sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    int total_permutations = h_factorial(NODES - 1);\n",
        "    int grid_size = (total_permutations + BLOCK_SIZE - 1) / BLOCK_SIZE;\n",
        "\n",
        "    double start_time = getTime();\n",
        "\n",
        "    // Launch kernel\n",
        "    tspKernel<<<grid_size, BLOCK_SIZE>>>(d_graph, d_result);\n",
        "\n",
        "    // Synchronize and get result\n",
        "    cudaDeviceSynchronize();\n",
        "    int result;\n",
        "    cudaMemcpy(&result, d_result, sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    double end_time = getTime();\n",
        "    double execution_time = end_time - start_time;\n",
        "\n",
        "    printf(\"Nodes: %d, Shortest Path: %d, Execution Time: %.6f seconds\\n\", NODES, result, execution_time);\n",
        "\n",
        "    // Clean up\n",
        "    cudaFree(d_graph);\n",
        "    cudaFree(d_result);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gGeQF-OnvlK",
        "outputId": "7d807fe6-df49-4a09-e5da-a50185ee55a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nodes: 4, Shortest Path: 80, Execution Time: 0.044314 seconds\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OZ5avDH4jLiB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}